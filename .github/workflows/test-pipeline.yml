name: Automated Testing Pipeline

on:
  push:
    branches: [ '**']
  pull_request:
    branches: [ '**' ]
  schedule:
    - cron: '0 2 * * *'  # Runs every night at 2:00 AM UTC
  workflow_dispatch:

jobs:
  build-and-setup:
    name: Build & Setup
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: |
            backend/package-lock.json
            frontend/package-lock.json
            ui-tests/package-lock.json
      
      - name: Install backend dependencies
        working-directory: ./backend
        run: npm ci
      
      - name: Install frontend dependencies
        working-directory: ./frontend
        run: npm ci
      
      - name: Install UI test dependencies
        working-directory: ./ui-tests
        run: npm ci
      
      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: |
            backend/node_modules
            frontend/node_modules
            ui-tests/node_modules
          key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}

  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: build-and-setup
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Install dependencies
        working-directory: ./backend
        run: npm ci
      
      - name: Run unit tests with coverage
        working-directory: ./backend
        run: |
          set -o pipefail
          npm run test:unit 2>&1 | tee unit-test-results.txt
      
      - name: Generate coverage report
        working-directory: ./backend
        run: |
          if [ -d "coverage" ]; then
            echo "Coverage report generated"
            ls -la coverage/
          fi
      
      - name: Upload coverage reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-report
          path: backend/coverage/

  integration-tests:
    name: Integration Tests (BDD)
    runs-on: ubuntu-latest
    needs: build-and-setup
    
    services:
      mongodb:
        image: mongo:latest
        ports:
          - 27017:27017
        options: >-
          --health-cmd "mongosh --eval 'db.adminCommand({ ping: 1 })'"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Install dependencies
        working-directory: ./backend
        run: npm ci
      
      - name: Start backend server
        working-directory: ./backend
        env:
          MONGODB_URI: mongodb://localhost:27017/todo_test
          PORT: 4001
        run: |
          npm start &
          sleep 5
      
      - name: Run BDD tests
        working-directory: ./backend
        run: |
          set -o pipefail
          npm run test:bdd 2>&1 | tee bdd-test-results.txt

  api-tests:
    name: API Tests
    runs-on: ubuntu-latest
    needs: build-and-setup
    
    services:
      mongodb:
        image: mongo:latest
        ports:
          - 27017:27017
        options: >-
          --health-cmd "mongosh --eval 'db.adminCommand({ ping: 1 })'"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Install dependencies
        working-directory: ./backend
        run: npm ci
      
      - name: Start backend server
        working-directory: ./backend
        env:
          MONGODB_URI: mongodb://localhost:27017/todo_test
          PORT: 4001
        run: |
          npm start &
          sleep 5
      
      - name: Run API tests
        working-directory: ./backend
        run: |
          set -o pipefail
          npm run test:api -- --reporters cli,json --reporter-json-export api-test-results.json 2>&1 | tee api-test-results.txt

  ui-tests:
    name: UI Tests
    runs-on: ubuntu-latest
    needs: build-and-setup
    
    services:
      mongodb:
        image: mongo:latest
        ports:
          - 27017:27017
        options: >-
          --health-cmd "mongosh --eval 'db.adminCommand({ ping: 1 })'"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Install backend dependencies
        working-directory: ./backend
        run: npm ci
      
      - name: Install frontend dependencies
        working-directory: ./frontend
        run: npm ci
      
      - name: Install UI test dependencies
        working-directory: ./ui-tests
        run: npm ci
      
      - name: Install Chrome and ChromeDriver
        run: |
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
      
      - name: Start backend server
        working-directory: ./backend
        env:
          MONGODB_URI: mongodb://localhost:27017/todo_test
          PORT: 4001
        run: |
          npm start &
          sleep 5
      
      - name: Build and start frontend
        working-directory: ./frontend
        run: |
          npm run build
          npm run preview -- --port 5174 --host 0.0.0.0 &
          sleep 10
          curl -f http://localhost:5174 || echo "Frontend not ready yet"
      
      - name: Run UI tests
        working-directory: ./ui-tests
        run: |
          set -o pipefail
          npm test 2>&1 | tee ui-test-results.txt
        continue-on-error: true


  test-reporting:
    name: Test Reporting & Metrics
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, api-tests, ui-tests]
    if: always()
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Download all test results
        uses: actions/download-artifact@v4
        with:
          path: .
      
      - name: Organize test results
        run: |
          mkdir -p test-results
          
          # Copy test result files to expected locations
          if [ -f "unit-test-results/unit-test-results.txt" ]; then
            cp unit-test-results/unit-test-results.txt backend/unit-test-results.txt
          fi
          
          if [ -f "bdd-test-results/bdd-test-results.txt" ]; then
            cp bdd-test-results/bdd-test-results.txt backend/bdd-test-results.txt
          fi
          
          if [ -f "api-test-results/api-test-results.txt" ]; then
            cp api-test-results/api-test-results.txt backend/api-test-results.txt
          fi
          
          if [ -f "api-test-results/api-test-results.json" ]; then
            cp api-test-results/api-test-results.json backend/api-test-results.json
          fi
          
          if [ -f "ui-test-results/ui-test-results.txt" ]; then
            mkdir -p ui-tests
            cp ui-test-results/ui-test-results.txt ui-tests/ui-test-results.txt
          fi
      
      - name: Generate automated metrics report
        run: |
          node scripts/generate-metrics.js
        continue-on-error: true
      
      - name: Display metrics summary
        if: always()
        run: |
          echo "üìä Test Metrics Generated"
          echo ""
          if [ -f "test-results/metrics.json" ]; then
            cat test-results/metrics.json
          fi
      
      - name: Upload metrics report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: metrics-report
          path: |
            test-results/METRICS-REPORT.md
            test-results/metrics.json
            backend/unit-test-results.txt
            backend/bdd-test-results.txt
            backend/api-test-results.txt
            backend/api-test-results.json
            ui-tests/ui-test-results.txt
      
      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-html-report
          path: coverage-report/
      
      - name: Comment PR with metrics
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            let report = '# üß™ Test Automation Results\n\n';
            
            if (fs.existsSync('test-results/METRICS-REPORT.md')) {
              const fullReport = fs.readFileSync('test-results/METRICS-REPORT.md', 'utf8');
              
              // Extract only executive summary for PR comment
              const summaryMatch = fullReport.match(/## üìä Executive Summary([\s\S]*?)---/);
              if (summaryMatch) {
                report += summaryMatch[0];
              }
              
              // Add quality gates
              const gatesMatch = fullReport.match(/## 5\. Quality Gates Status([\s\S]*?)---/);
              if (gatesMatch) {
                report += '\n' + gatesMatch[0];
              }
              
              report += '\nüìÑ **Full Report**: Download the `metrics-report` artifact for detailed analysis.\n';
            } else {
              report += '‚ö†Ô∏è Metrics report generation failed. Check workflow logs.\n';
            }
            
            try {
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: report
              });
            } catch (error) {
              console.log('Could not post comment:', error.message);
            }
      
      - name: Evaluate quality gates
        if: always()
        run: |
          if [ -f "test-results/metrics.json" ]; then
            # Check if quality gates passed
            STATUS=$(cat test-results/metrics.json | grep -o '"overall":"[^"]*"' | cut -d'"' -f4 || echo "UNKNOWN")
            
            echo "Quality Gate Status: $STATUS"
            
            if [[ "$STATUS" == *"FAILED"* ]]; then
              echo "‚ùå Quality gates failed!"
              echo "::error::Quality gates failed. Check metrics report for details."
              exit 1
            else
              echo "‚úÖ All quality gates passed!"
            fi
          else
            echo "‚ö†Ô∏è No metrics file found, skipping quality gate check"
          fi
